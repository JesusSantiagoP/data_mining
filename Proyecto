# -*- coding: utf-8 -*-
"""Proyecto Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15996s9deUTgtHBT71jxgQPUKnCc3FIlu

###**Proyecto Final**

###**Costos de Gastos Médicos en EU**

Integrantes:

Reyes Velasco Alondra Belem

Santiago Pacheco Jesús Alberto

## Entendimiento de los datos
"""

from google.colab import files

uploaded=files.upload()

uploaded

pip install missingno

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import missingno as msno
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('datasets_insurance.csv')
df.shape

df.columns.values.tolist()

df.info()

df.head()

df.tail()

# Corroborar que no haya valores faltantes
df.isnull().any().any()

df.describe()

# Números de valores únicos de cada columna
df.agg(['count','size','nunique'])

# Números de valores únicos por género
df.groupby('genero').agg(['count','size','nunique']).stack()

# Números de valores únicos por fumador
df.groupby('fumador').agg(['count','size','nunique']).stack()

# Cargo promedio de fumadores
df['cargos'][df['fumador'] == 'yes'].mean()

# Cargo promedio de no fumadores
df['cargos'][df['fumador'] == 'no'].mean()

# Cargo promedio de mujeres
df['cargos'][df['genero'] == 'female'].mean()

# Cargo promedio de hombres
df['cargos'][df['genero'] == 'male'].mean()

"""## Visualización de los Datos"""

plt.figure(figsize=(20,8))
# Gráfica de la Distribución de los Cargos
plt.subplot(1,2,1)
plt.title('Distribución del Costo del Seguro')
sns.distplot(df.cargos)
# Flexibly plot a univariate distribution of observations.

plt.subplot(1,2,2)
plt.title('Costo del Seguro')
sns.boxplot(y=df.cargos)
plt.show()

# Gráfica del Género
plt.figure(figsize=(25, 6))

plt.subplot(1,3,1)
plt1 = df.genero.value_counts().plot(kind='bar')
plt.title('Histograma de Género')
plt1.set(xlabel = 'genero', ylabel='Frequency')

plt.show()

df1 = pd.DataFrame(df.groupby(['genero'])['cargos'].mean().sort_values(ascending = False))
df1.plot.bar(color='green')
plt.title('Genero vs Costos Promedio')
plt.show()

# Gráfica de la Región
plt.figure(figsize=(25, 6))

plt.subplot(1,3,1)
plt2 = df.region.value_counts().plot(kind='bar')
plt.title('Histograma Region')
plt2.set(xlabel = 'Region', ylabel='Frequency')

plt.show()

# IMC vs Cargos
df['rango_IMC'] = df['IMC'].apply(lambda x : "thin" if x < 19
                                                     else ("fit" if  19 <= x < 25
                                                           else ("overweight" if  25 <= x < 28
                                                                else ("Obese"))))
df2 = pd.DataFrame(df.groupby(['rango_IMC'])['cargos'].mean().sort_values(ascending = False))
df2.plot.bar(color='orange')
plt.title('Rango IMC vs Costos Promedio')
plt.show()

# Gráfica Edad
# Cofiguración de niveles por precio del seguro:
df['rango_edad'] = df['edad'].apply(lambda x : "low" if x < 25 
                                                     else ("Medium" if 25 <= x < 40
                                                           else ("High")))
df.head()
plt.figure(figsize=(25, 6))

plt.subplot(1,3,1)
plt3 = df.rango_edad.value_counts().plot(kind='bar')
plt.title('Histograma del rango por edad')
plt3.set(xlabel = 'rango_edad', ylabel='Frequency')

plt.show()

# Gráfica número de hijos
fig, ax = plt.subplots(figsize = (15,5))
plt4 = sns.countplot(df['hijos'], order=pd.value_counts(df['hijos']).index,)
plt4.set(xlabel = 'No. de hijos', ylabel= 'No. de hijos')
plt.show()
plt.tight_layout()

# Gráfica Fumadores / No fumadores
plt.figure(figsize=(15,5))

plt.subplot(1,2,1)
plt.title('Histograma Fumadores')
sns.countplot(df.fumador, palette=("RdBu"))

plt.subplot(1,2,2)
plt.title('Fumador vs Costo')
sns.boxplot(x=df.fumador, y=df.cargos, palette=("RdBu"))

plt.show()

df3 = pd.DataFrame(df.groupby(['fumador'])['cargos'].mean().sort_values(ascending = False))
df3.plot.bar(color='purple')
plt.title('Fumador vs Costo Promedio')
plt.show()

"""## Preprocesamiento de los Datos"""

df.columns.values.tolist() # Se agregaron las columnas de rango_IMC y rango_edad

df.dtypes # Las columnas agregadas son variables categóricas

data = df.copy()

data.head()

"""### Selección de variables numéricas"""

import statsmodels.api as sm

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso

"""Método de filtrado (Correlación de Pearson)"""

plt.figure(figsize=(12,10))
cor = data.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

# Correlación respecto a la variable de salida o target
cor_target = abs(cor["cargos"])

# Selección de características altamente correlacionadas
relevant_features = cor_target[cor_target>0.5]
relevant_features

"""Método Integrado (Embedded Method)"""

reg = LassoCV()
X1 = ['edad', 'IMC', 'hijos']
reg.fit(data[X1], data['cargos'])
coef = pd.Series(reg.coef_, index = data[X1].columns)
print("Número óptimo de características:" + str(sum(coef != 0)))
print("Desempeño mediante la regularización Lasso: %f" %reg.score(data[X1],data['cargos']))

imp_coef = coef.sort_values()
import matplotlib
matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)
imp_coef.plot(kind = "barh")
plt.title("Importancia de las características usando el modelo de Lasso")

"""### Selección de características (entrada categórica y salida numérica)"""

from sklearn.preprocessing import OrdinalEncoder 
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectKBest, mutual_info_regression

# Convertimos la variable hijos a string
def replace_name(a,b):
    data.hijos.replace(a,b,inplace=True)

replace_name(0,'0hijos')
replace_name(1,'1hijos')
replace_name(2,'2hijos')
replace_name(3,'3hijos')
replace_name(5,'5hijos')
replace_name(6,'6hijos')

data['hijos']

X2 = data[['genero','hijos','fumador','region','rango_IMC','rango_edad']] # Características
y1 = data[['cargos']]                                                     # Target
X2 = X2.astype(str)  # Restringir que los datos de entrada sean string

# Dividimos en train (80%) y test (20%)
X2_train, X2_test, y1_train, y1_test = train_test_split(X2, y1, test_size=0.20, random_state=1)

# Checamos las dimensiones
print('Train', X2_train.shape, y1_train.shape)
print('Test', X2_test.shape, y1_test.shape)

# prepare input data
def prepare_inputs(X_train, X_test):
    oe = OrdinalEncoder()
    oe.fit(X_train)
    X2_train_enc = oe.transform(X_train)
    X2_test_enc = oe.transform(X_test)
    return X2_train_enc, X2_test_enc

# Preparamos los datos de entrada o características
X2_train_enc, X2_test_enc = prepare_inputs(X2_train, X2_test)

"""Mutual Information Regression"""

def select_features(X_train, y_train, X_test):
	fs = SelectKBest(score_func=mutual_info_regression, k='all')
	fs.fit(X_train, y_train)
	X2_train_fs = fs.transform(X_train)
	X2_test_fs = fs.transform(X_test)
	return X2_train_fs, X2_test_fs, fs

# Selección de características con Mutual Info Regression
X2_train_fs, X2_test_fs, fs = select_features(X2_train_enc, y1_train, X2_test_enc)

for i in range(len(fs.scores_)):
  print('Características %d: %f' % (i+1,fs.scores_[i]))

plt.bar([i+1 for i in range(len(fs.scores_))], fs.scores_)

"""Las variables significativas son:
rango_edad, fumador, genero, hijos y rango_IMC
"""

# Eliminamos las variables no significativas: región, edad e IMC

"""## Modelado"""

atributos = data[['rango_edad','genero','rango_IMC','hijos','fumador']]
y = data[['cargos']]

# Manejo de Datos Categóricos

def encode(x,df):
    temp = pd.get_dummies(df[x], drop_first = True)
    df = pd.concat([df, temp], axis = 1)
    df.drop([x], axis = 1, inplace = True)
    return df

atributos = encode('rango_edad', atributos)
atributos = encode('genero', atributos)
atributos = encode('rango_IMC', atributos)
atributos = encode('fumador', atributos)
atributos = encode('hijos', atributos)

# Dividimos los datos de entrenamiento (80%) y prueba (20%)
np.random.seed(0)
X_train, X_test, y_train, y_test = train_test_split(atributos, y, train_size=0.80, test_size=0.20, random_state=100)

# Checamos las dimensiones
print('Train', X_train.shape, y_train.shape)
print('Test', X_test.shape, y_test.shape)

import statsmodels.api as sm
model = sm.OLS(y_train, X_train.astype(float)).fit()
model.summary()

def build_model(X,y):
    X = sm.add_constant(X) #Adding the constant
    lm = sm.OLS(y,X).fit() # fitting the model
    print(lm.summary()) # model summary
    return X

X_train_new = build_model(X_train.astype(float),y_train)

# Eliminan variables pocos significativas (i.e P.values > 0.05)
X_train_new = X_train.drop(['male','0hijos','1hijos','2hijos','3hijos','5hijos','thin'], axis = 1)

X_train_new = build_model(X_train_new.astype(float),y_train)

# Predicción
lm = sm.OLS(y_train,X_train_new).fit()
y_train_price = lm.predict(X_train_new)

# Histograma de los errores
fig = plt.figure()
sns.distplot((y_train.values - y_train_price.values), bins = 20)
fig.suptitle('Error Terms', fontsize = 20)
plt.xlabel('Errors', fontsize = 18)

# Se usará el modelo para las predicciones
X_train_new = X_train_new.drop('const',axis=1)

# Creamos un nuevo dataframe quitando las variables de X_test
X_test_new = X_test[X_train_new.columns]

# Se agrega la variable constate
X_test_new = sm.add_constant(X_test_new)

y_pred = lm.predict(X_test_new.astype(float))

from sklearn.metrics import r2_score 
r2_score(y_test, y_pred)

"""## Evaluación del Modelo"""

# Gráfica de y_test vs y_pred
fig = plt.figure()
plt.scatter(y_test,y_pred)
fig.suptitle('y_test vs y_pred', fontsize=20)
plt.xlabel('y_test', fontsize=18)
plt.ylabel('y_pred', fontsize=16)

"""## Validación"""

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

np.random.seed(0)
X_train, X_test, y_train, y_test = train_test_split(atributos, y, train_size=0.80, test_size=0.20, random_state=100)
kf = KFold(n_splits=5)
clf = LinearRegression()
clf.fit(X_train,y_train)

score = clf.score(X_train, y_train)
print("Metrica del modelo ", score)

scores = cross_val_score(clf,X_train,y_train,cv=kf)
print("Accuracy", scores)

#Por tanto, la puntuación media y el intervalo de confianza del 95% de la estimación de la puntuación vienen dados por:
print("Accuracy: %0.6f (+/- %0.4f)" % (scores.mean(),scores.std()*2))

"""R^2"""

y_pred1 = clf.predict(X_test)
score_pred1 = r2_score(y_test, y_pred1)
print("Metrica en Test", score_pred1)

"""Error Cuadrático Medio"""

score_pred2 = mean_squared_error(y_test, y_pred)
print("Metrica en Test", score_pred2)

"""##Cluster(Prueba)"""


